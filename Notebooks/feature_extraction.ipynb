{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus= [\"apple ball cat\", \"ball cat dog elephant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features=4\n",
    "n_grams= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert a collection of text to a matrix of token counts\n",
    "vectorizer= CountVectorizer(max_features= max_features, ngram_range=(1,n_grams))\n",
    "X= vectorizer.fit_transform(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 1]\n",
      " [0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple' 'ball' 'ball cat' 'cat']\n"
     ]
    }
   ],
   "source": [
    "print(vectorizer.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing feature extraction\n",
    "import os\n",
    "import numpy as np\n",
    "from src.utils.common import get_df\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4186249</td>\n",
       "      <td>1</td>\n",
       "      <td>Searching and capturing a character using regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54312</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Yes, of course there is :-) object oriente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7956164</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;Try waiting for window's &lt;code&gt;load&lt;/code&gt;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  label                                               text\n",
       "0  4186249      1  Searching and capturing a character using regu...\n",
       "1    54312      0   <p>Yes, of course there is :-) object oriente...\n",
       "2  7956164      0   <p>Try waiting for window's <code>load</code>..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_train= pd.read_csv('/Users/nithinpradeep/Projects/NLP-classification-with-DVC/artifacts/prepared/train.tsv',\n",
    "                delimiter=\"\\t\",\n",
    "                encoding='utf-8',\n",
    "                header=None,\n",
    "                names=[\"id\",\"label\",\"text\"])\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'searching and capturing a character using regular expressions python <p>while going through one of the problems in <a href=\"http://www.pythonchallenge.com/\" rel=\"nofollow\">python challenge</a>, i am trying to solve it as follows:</p> <p>read the input in a text file with characters as follows:</p> <pre><code>dqheabsamljtmaokmnslzivmenfxqdatqijitwtychyemwqtnxbblxwzngmdqhhxnlhfeyvzxmhsxzd bebaxeapgqpttvqrvxhpeoutisttpdeeugfgmdkkqceyjusuigrogfypzkqgvccdbkrcywhflvpzdmek myupxvgtgsvwgrybkonbeghqhuxhhnyjfwsftfaiwtaombzescsosumwpssjcpllblspigffdlpzzmkz jarrjufhgxdrzywwosrblprasvrupzlaubtdhgzqtvzovhevstbhpitdlluljvvwrwvhpnvzewvyhmps kmvcdehzfzxtwocgvakhhcnozrsbwsiehpenfjarjlwwcvkftlhuvsjcziyfpcyrojxopkxhvucqcuge luwlbcmqpwdvupubrrjzhfexhxsbvljqjvvfegruwrshpekujcpmpisrv....... </code></pre> <p>what i need is to go through this text file and pick all lower case letters that are enclosed by only three upper-case letters on each side.</p> <p>the python script that i wrote to do the above is as follows:</p> <pre><code>import re pattern = re.compile(\"[a-z][a-z]{3}([a-z])[a-z]{3}[a-z]\") f = open(\\'/users/dev/sometext.txt\\',\\'r\\') for line in f: result = pattern.search(line) if result: print result.groups() f.close() </code></pre> <p>the above given script, instead of returning the capture(list of lower case characters), returns all the text blocks that meets the regular expression criteria, like</p> <pre><code>axcsdfghj vcdfetyha nhjuikjho ......... ......... </code></pre> <p>can somebody tell me what exactly i am doing wrong here? and instead of looping through the entire file, is there an alternate way to run the regular expression search on the entire file?</p> <p>thanks</p>'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_words= np.array(df_train.text.str.lower().values.astype(\"U\"))#convert to unicode\n",
    "train_words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17536x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 33149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "bag_of_words = CountVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        max_features=max_features,\n",
    "        ngram_range=(1, n_grams)\n",
    "    )\n",
    "bag_of_words.fit(train_words)\n",
    "train_words_binary_matrix = bag_of_words.transform(train_words)\n",
    "train_words_binary_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<17536x4 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 33149 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfTransformer(smooth_idf=False)\n",
    "tfidf.fit(train_words_binary_matrix)\n",
    "train_words_tfidf_matrix = tfidf.transform(train_words_binary_matrix)\n",
    "train_words_tfidf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
